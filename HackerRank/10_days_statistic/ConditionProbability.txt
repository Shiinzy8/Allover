Если два события произошли независимо и последовательно, но вероятность первого не влияла на вероятность второго
То можно утверждать:
    P(B | A) = P(B) - событие A никак не влияло на событие B

Если вероятность события А влияет на вероятность события B то это называется пересечением событий - intersection of events
То можно утверждать:
    P(A n B) = P(A) * P(B | A) - сначало возникло событие А с вероятностью P(A) потом оно повлияло но возникновение события B
                                 P(B | A)
можно сделать вывод что вероятность события B:
    P(B | A) = P(A n B) / P(A)

Теорема Байеса
    Дано два события A и B
    P(A | B) - вероятность возникновения A если B уже возникло
    P(B | A) - вероятность возникновения B если A уже возникло
Сама теорема:
    P(A n B) вероятность возникновения двух событий = P(B|A) * P(A) = P(A|B) * P(B);
    P(B|A) * P(A) = P(A|B) * P(B);
    P(A|B) = P(B|A) * P(A) / P(B) = P(B|A) * P(A) / (P(B|A) * P(A) + P(B|A') * P(A'));

P(B) обычно вычисляется по формуле полной вероятности события, зависящего от нескольких несовместных гипотез, имеющих суммарную вероятность 1.
P(B|A) * P(A) / (P(B|A) * P(A) + P(B|A') * P(A'))
то есть вероятность B после того как прозошло событие A и вероятность B после того как событие A не произошло

Пример:
Пусть вероятность брака у первого рабочего p_{i} p_{1} = 09, 
    второго — p_{2} = 0,5, 
    третьего — p_{3} = 0,2. 
Первый изготовил n_{i} n_{1}=800} деталей, 
    второй — n_{2} = 600 деталей, 
    третий — n_{3} = 900 деталей.
Начальник цеха берёт случайную деталь, и она оказывается бракованной. 
Спрашивается, с какой вероятностью эту деталь изготовил третий рабочий?

Событие B — брак детали, событие A_{i} — деталь произвёл рабочий i.
P(A_{i}) - вероятность того что деталь произвел рабочий такой то = количество деталей который рабочий изготовил / общее количество деталей
P(B | A_{i}) - вероятность брака для конкретного рабочего

Тогда P(A_{i})=n_{i}/N, где N=n_{1}+n_{2}+n_{3}, а P(B | A_{i})=p_{i}.

По формуле полной вероятности

Голубой неоновый знак, обозначающий простое выражение формулы Байеса
Теорема Байеса (или формула Байеса) — одна из основных теорем элементарной теории вероятностей, которая позволяет определить вероятность какого-либо события при условии, что произошло другое статистически взаимозависимое с ним событие. Другими словами, по формуле Байеса можно более точно пересчитать вероятность, взяв в расчет как ранее известную информацию, так и данные новых наблюдений. Формула Байеса может быть выведена из основных аксиом теории вероятностей, в частности из условной вероятности. Особенность теоремы Байеса заключается в том, что для её практического применения требуется большое количество расчетов, вычислений, поэтому байесовские оценки стали активно использовать только после революции в компьютерных и сетевых технологиях.

При возникновении теоремы Байеса вероятности, используемые в теореме, подвергались целому ряду вероятностных интерпретаций. В одной из таких интерпретаций говорилось, что вывод формулы напрямую связан с применением особого подхода к статистическому анализу. Если использовать байесовскую интерпретацию вероятности, то теорема показывает, как личный уровень доверия может кардинально измениться вследствие количества наступивших событий. В этом заключаются выводы Байеса, которые стали основополагающими для байесовской статистики. Однако теорема используется не только в байесовском анализе, но и активно применяется для большого ряда других расчетов.

Психологические эксперименты[1] показали, что люди часто неверно оценивают вероятность события, на основе полученного опыта (апостериорная вероятность), поскольку игнорируют саму вероятность предположения (априорная вероятность). Поэтому правильный результат по формуле Байеса может сильно отличаться от интуитивно ожидаемого.

Теорема Байеса названа в честь её автора Томаса Байеса (1702—1761) — английского математика и священника, который первым предложил использование теоремы для корректировки убеждений, основываясь на обновлённых данных. Его работа «An Essay towards solving a Problem in the Doctrine of Chances» впервые опубликована в 1763 году[2], через 2 года после смерти автора. До того, как посмертная работа Байеса была принята и прочитана в Королевском обществе, она была значительно отредактирована и обновлена Ричардом Прайсом. Однако эти идеи не предавались публичной огласке до тех пор, пока не были вновь открыты и развиты Лапласом, впервые опубликовавшим современную формулировку теоремы в своей книге 1812 года «Аналитическая теория вероятностей».

Сэр Гарольд Джеффрис писал, что теорема Байеса «для теории вероятности, то же, что теорема Пифагора для геометрии»[3].


Содержание
1	Формулировка
2	Доказательство
2.1	Вычисление {\displaystyle P(B)} P(B)
2.2	«Физический смысл» и терминология
3	Примеры
3.1	Пример 1
3.2	Пример 2
3.3	Пример 3
3.4	Пример 4 — парадокс теоремы Байеса
4	Варианты интерпретации вероятностей в теореме Байеса
4.1	Интерпретация Байеса
4.2	Частотная интерпретация
5	Формы
5.1	События
5.1.1	Простая форма
5.1.2	Расширенная форма
5.2	Непрерывные случайные величины
5.2.1	Простая форма
5.2.2	Расширенная форма
5.3	Правило Байеса
6	Вывод формул
6.1	Для событий
6.2	Для случайных переменных
7	См. также
8	Примечания
9	Литература
10	Для дальнейшего изучения
11	Ссылки
Формулировка
Основная статья: Байесовская вероятность
Формула Байеса:

{\displaystyle P(A\mid B)={\frac {P(B\mid A)\,P(A)}{P(B)}}} {\displaystyle P(A\mid B)={\frac {P(B\mid A)\,P(A)}{P(B)}}},
где

{\displaystyle P(A)} P(A) — априорная вероятность гипотезы A (смысл такой терминологии см. ниже);
{\displaystyle P(A\mid B)} {\displaystyle P(A\mid B)} — вероятность гипотезы A при наступлении события B (апостериорная вероятность);
{\displaystyle P(B\mid A)} {\displaystyle P(B\mid A)} — вероятность наступления события B при истинности гипотезы A;
{\displaystyle P(B)} P(B) — полная вероятность наступления события B.
Доказательство
Формула Байеса вытекает из определения условной вероятности. Вероятность совместного события {\displaystyle AB} AB двояко выражается через условные вероятности

{\displaystyle P(AB)=P(A\mid B)P(B)=P(B\mid A)P(A)} {\displaystyle P(AB)=P(A\mid B)P(B)=P(B\mid A)P(A)}
Следовательно {\displaystyle P(A\mid B)={\frac {P(AB)}{P(B)}}={\frac {P(B\mid A)\,P(A)}{P(B)}}} {\displaystyle P(A\mid B)={\frac {P(AB)}{P(B)}}={\frac {P(B\mid A)\,P(A)}{P(B)}}}

Вычисление {\displaystyle P(B)} P(B)
В задачах и статистических приложениях {\displaystyle P(B)} P(B) обычно вычисляется по формуле полной вероятности события, зависящего от нескольких несовместных гипотез, имеющих суммарную вероятность 1.

{\displaystyle P(B)=\sum _{i=1}^{N}P(A_{i})P(B\mid A_{i})} {\displaystyle P(B)=\sum _{i=1}^{N}P(A_{i})P(B\mid A_{i})},
где вероятности под знаком суммы известны или допускают экспериментальную оценку.

В этом случае формула Байеса записывается так:

{\displaystyle P(A_{j}\mid B)={\frac {P(A_{j})P(B\mid A_{j})}{\sum _{i=1}^{N}P(A_{i})P(B\mid A_{i})}}} {\displaystyle P(A_{j}\mid B)={\frac {P(A_{j})P(B\mid A_{j})}{\sum _{i=1}^{N}P(A_{i})P(B\mid A_{i})}}}
«Физический смысл» и терминология
Формула Байеса позволяет «переставить причину и следствие»: по известному факту события вычислить вероятность того, что оно было вызвано данной причиной.

События, отражающие действие «причин», в данном случае называют гипотезами, так как они — предполагаемые события, повлекшие данное. Безусловную вероятность справедливости гипотезы называют априорной (насколько вероятна причина вообще), а условную — с учётом факта произошедшего события — апостериорной (насколько вероятна причина оказалась с учетом данных о событии).

Примеры
Пример 1
Событие {\displaystyle A} A — в баке нет топлива, событие {\displaystyle B} B — машина не заводится. Заметим, что вероятность {\displaystyle P(B\mid A)} {\displaystyle P(B\mid A)} того, что машина не заведется, если в баке нет топлива, равняется единице. Тем самым, вероятность {\displaystyle P(A)} P(A) того, что в баке нет топлива, равна произведению вероятности {\displaystyle P(B)} P(B) того, что машина не заводится, на вероятность {\displaystyle P(A\mid B)} {\displaystyle P(A\mid B)} того, что причиной события {\displaystyle B} B стало именно отсутствие топлива (событие {\displaystyle A} A), а не, к примеру, разряженный аккумулятор.

Пример 2
Пусть вероятность брака у первого рабочего {\displaystyle p_{1}=0{,}9} p_{1}=0{,}9, у второго рабочего — {\displaystyle p_{2}=0{,}5} p_{2}=0{,}5, а у третьего — {\displaystyle p_{3}=0{,}2} p_{3}=0{,}2. Первый изготовил {\displaystyle n_{1}=800} n_{1}=800 деталей, второй — {\displaystyle n_{2}=600} n_{2}=600 деталей, а третий — {\displaystyle n_{3}=900} n_{3}=900 деталей. Начальник цеха берёт случайную деталь, и она оказывается бракованной. Спрашивается, с какой вероятностью эту деталь изготовил третий рабочий?

Событие {\displaystyle B} B — брак детали, событие {\displaystyle A_{i}} A_{i} — деталь произвёл рабочий {\displaystyle i} i. Тогда {\displaystyle P(A_{i})=n_{i}/N} P(A_{i})=n_{i}/N, где {\displaystyle N=n_{1}+n_{2}+n_{3}} N=n_{1}+n_{2}+n_{3}, а {\displaystyle P(B\mid A_{i})=p_{i}} {\displaystyle P(B\mid A_{i})=p_{i}}.

По формуле полной вероятности:

    P(B)=P(B | A_{1}) * P(A_{1}) + P(B | A_{2}) * P(A_{2}) + P(B | A_{3}) * P(A_{3})
    формулу можно интерпретивароть как то что брак уже получен P(B) (вероятность брака для всех рабочих),
    значит кто то из рабочих ее точно допустил

По формуле полной вероятности:

    P(A_{3} | B) = P(B | A_{3}) * P(A_{3}) / P(B)
                 = (P(B | A_{3}) * P(A_{3})) / (P(B | A_{1}) * P(A_{1}) + P(B | A_{2}) * P(A_{2}) + P(B | A_{3}) * P(A_{3}))
                 = (p_{3} * n_{3} / N) / (p_{1} * n_{1} / N + p_{2} * n_{2} / N + p_{3} * n_{3} / N)
                 = (0,2 * 900 /2300) / ((0,9 * 800 /2300) + (0,5 * 600 /2300) + (0,2 * 900 /2300))
                 = 0.15
                 = 15 %
